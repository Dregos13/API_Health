{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inteligencia de Negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/1200px-Pandas_logo.svg.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T09:11:55.677893Z",
     "start_time": "2020-10-06T09:11:55.673674Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bson'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbson\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobjectid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObjectId\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MongoClient\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bson'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from bson.objectid import ObjectId\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Todos los imports necesarios para realizar la practica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:37017\")\n",
    "id = \"6277b7f6f61ac33ff10897bd\"\n",
    "archivo = db['archive']\n",
    "usuario = db['user']\n",
    "entrenamiento = db['entrenamiento']\n",
    "records = db['records']\n",
    "objInstance = ObjectId(id)\n",
    "df = pandas.DataFrame(list(entrenamiento.find()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lectura del csv, lo almacenamos en 2 dataframes para realizar analisis de distintos tipos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "lclase = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creamos las variables que nos serviran para los objetos de la clase que nos permite normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "media = df.sum(axis = 0, skipna = True, numeric_only=int);\n",
    "resul  = media[4] / (len(df.index));\n",
    "df[\"Cholesterol\"].replace({0 : resul}, inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Para colesterol, arreglamos los valores que están a 0, para ello haciendo una media de todos los valores, reemplazamos los nulos para que al la hora de hacer el estudio no tengan datos vacíos que estropeen el resultado en mayor medida que teniendo la media.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['ChestPainType'] = le.fit_transform(df['ChestPainType'])\n",
    "df['Sex'] = le.fit_transform(df['Sex'])\n",
    "df['RestingECG'] = le.fit_transform(df['RestingECG'])\n",
    "df['ExerciseAngina'] = le.fit_transform(df['ExerciseAngina'])\n",
    "df['ST_Slope'] = le.fit_transform(df['ST_Slope'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Normalizamos los datos, ya que los algoritmos no trabjan con String, convertimos cada valor en enteros.\n",
    "Una vez realizado pasamos a trabajor con los Kfold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "cols = [col for col in df.columns if col not in ['HeartDisease']]\n",
    "data = df[cols]\n",
    "target = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creamos el Kfold, en el que le indicamos que queremos separar los datos en 5 partes, donde en cada iteración, el entrenamiento irá variando. El target se quita del entrenamiento, sino daría 1 la predicción. El target será el heartdisease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "media = 0\n",
    "\n",
    "vpositivos = 0\n",
    "fpositivos = 0\n",
    "vnegativos = 0\n",
    "fnegativos = 0\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "\n",
    "    data_train2, data_test2 = data.iloc[train_index], data.iloc[test_index]\n",
    "\n",
    "    target_train2, target_test2 = target.iloc[train_index], target.iloc[test_index]\n",
    "\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    model1 = gnb.fit(data_train2, target_train2)\n",
    "\n",
    "    pred1 = model1.predict(data_test2)\n",
    "\n",
    "    precision = accuracy_score(target_test2, pred1, normalize = True)\n",
    "\n",
    "    m = confusion_matrix(target_test2, pred1)\n",
    "\n",
    "    total = m.sum()\n",
    "\n",
    "    vpositivos += m[0,0]\n",
    "    fpositivos += m[0,1]\n",
    "    vnegativos += m[1,1]\n",
    "    fnegativos += m[1,0]\n",
    "\n",
    "    print(\"Naive-Bayes accuracy : \",precision)\n",
    "\n",
    "    media = media + precision\n",
    "\n",
    "media = media / 5\n",
    "\n",
    "print(\"Verdadero Positivos:\", vpositivos)\n",
    "print(\"Falsos Positivos:\", fpositivos)\n",
    "print(\"Verdadero Negativos:\", vnegativos)\n",
    "print(\"Falsos Negativos:\", fnegativos)\n",
    "\n",
    "matrix = np.array([[vpositivos,fpositivos],[fnegativos,vnegativos]])\n",
    "\n",
    "print(media)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Del bucle obtenemos por cada iteración un resultado. Lo primero es que para hacer el bucle tenemos que dividir los indices de que datos son para testeo y cuales son para entrenamiento, los separamos del dataframe y los usamos para el fit, en este caso será para el modelo GaussianoNB de Naive Bayens. Obtenemos la matriz de confusión y separamos las valores, para obtener el valor final completo.\n",
    "\n",
    "Para el resto de analisis serán iguales en procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "media = 0\n",
    "\n",
    "vpositivos = 0\n",
    "fpositivos = 0\n",
    "vnegativos = 0\n",
    "fnegativos = 0\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "\n",
    "    data_train2, data_test2 = data.iloc[train_index], data.iloc[test_index]\n",
    "\n",
    "    target_train2, target_test2 = target.iloc[train_index], target.iloc[test_index]\n",
    "\n",
    "    svc_model = LinearSVC(random_state=10, max_iter=4000)\n",
    "\n",
    "    svc_model.fit(data_train2, target_train2)\n",
    "\n",
    "    pred2 = svc_model.predict(data_test2)\n",
    "\n",
    "    precision = accuracy_score(target_test2, pred2, normalize=True)\n",
    "\n",
    "    m = confusion_matrix(target_test2, pred2)\n",
    "\n",
    "    total = m.sum()\n",
    "\n",
    "    vpositivos += m[0,0]\n",
    "    fpositivos += m[0,1]\n",
    "    vnegativos += m[1,1]\n",
    "    fnegativos += m[1,0]\n",
    "\n",
    "    print(\"SVC accuracy : \", precision)\n",
    "\n",
    "    media = media + precision\n",
    "\n",
    "media = media / 5\n",
    "\n",
    "print(\"Verdadero Positivos:\", vpositivos)\n",
    "print(\"Falsos Positivos:\", fpositivos)\n",
    "print(\"Verdadero Negativos:\", vnegativos)\n",
    "print(\"Falsos Negativos:\", fnegativos)\n",
    "\n",
    "matrix = np.array([[vpositivos,fpositivos],[fnegativos,vnegativos]])\n",
    "\n",
    "print(media)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "media = 0\n",
    "\n",
    "vpositivos = 0\n",
    "fpositivos = 0\n",
    "vnegativos = 0\n",
    "fnegativos = 0\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "df2 = pd.get_dummies(df2, columns=['ChestPainType'])\n",
    "\n",
    "cols = [col for col in df2.columns if col not in ['HeartDisease']]\n",
    "\n",
    "df2['Sex'] = le.fit_transform(df2['Sex'])\n",
    "df2['RestingECG'] = le.fit_transform(df2['RestingECG'])\n",
    "df2['ExerciseAngina'] = le.fit_transform(df2['ExerciseAngina'])\n",
    "df2['ST_Slope'] = le.fit_transform(df2['ST_Slope'])\n",
    "\n",
    "data = df2[cols]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(data)\n",
    "data = pd.DataFrame(x_scaled)\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "\n",
    "    data_train2, data_test2 = data.iloc[train_index], data.iloc[test_index]\n",
    "\n",
    "    target_train2, target_test2 = target.iloc[train_index], target.iloc[test_index]\n",
    "\n",
    "    neigh.fit(data_train2, target_train2)\n",
    "\n",
    "    pred2 = neigh.predict(data_test2)\n",
    "\n",
    "    precision = accuracy_score(target_test2, pred2, normalize=True)\n",
    "\n",
    "    m = confusion_matrix(target_test2, pred2)\n",
    "\n",
    "    total = m.sum()\n",
    "\n",
    "    vpositivos += m[0,0]\n",
    "    fpositivos += m[0,1]\n",
    "    vnegativos += m[1,1]\n",
    "    fnegativos += m[1,0]\n",
    "\n",
    "    print(\"KNN accuracy : \", precision)\n",
    "\n",
    "    media = media + precision\n",
    "\n",
    "print(\"Verdadero Positivos:\", vpositivos)\n",
    "print(\"Falsos Positivos:\", fpositivos)\n",
    "print(\"Verdadero Negativos:\", vnegativos)\n",
    "print(\"Falsos Negativos:\", fnegativos)\n",
    "\n",
    "media = media / 5\n",
    "\n",
    "print(media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "media = 0\n",
    "\n",
    "vpositivos = 0\n",
    "fpositivos = 0\n",
    "vnegativos = 0\n",
    "fnegativos = 0\n",
    "\n",
    "cols = [col for col in df.columns if col not in ['HeartDisease']]\n",
    "df3 = df[cols];\n",
    "\n",
    "for train_index, test_index in kf.split(df3):\n",
    "\n",
    "    data_train2, data_test2 = df3.iloc[train_index], df3.iloc[test_index]\n",
    "\n",
    "    target_train2, target_test2 = target.iloc[train_index], target.iloc[test_index]\n",
    "\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    clf = clf.fit(data_train2, target_train2)\n",
    "\n",
    "    pred2 = clf.predict(data_test2)\n",
    "\n",
    "    precision = accuracy_score(target_test2, pred2, normalize=True)\n",
    "\n",
    "    m = confusion_matrix(target_test2, pred2)\n",
    "\n",
    "    total = m.sum()\n",
    "\n",
    "    vpositivos += m[0,0]\n",
    "    fpositivos += m[0,1]\n",
    "    vnegativos += m[1,1]\n",
    "    fnegativos += m[1,0]\n",
    "\n",
    "    print(\"Tree accuracy : \", precision)\n",
    "\n",
    "    media = media + precision\n",
    "\n",
    "print(\"Verdadero Positivos:\", vpositivos)\n",
    "print(\"Falsos Positivos:\", fpositivos)\n",
    "print(\"Verdadero Negativos:\", vnegativos)\n",
    "print(\"Falsos Negativos:\", fnegativos)\n",
    "\n",
    "media = media / 5\n",
    "\n",
    "print(media)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "media = 0\n",
    "\n",
    "vpositivos = 0\n",
    "fpositivos = 0\n",
    "vnegativos = 0\n",
    "fnegativos = 0\n",
    "\n",
    "for train_index, test_index in kf.split(df3):\n",
    "\n",
    "    data_train2, data_test2 = df3.iloc[train_index], df3.iloc[test_index]\n",
    "\n",
    "    target_train2, target_test2 = target.iloc[train_index], target.iloc[test_index]\n",
    "\n",
    "    randomtree = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "    clf = randomtree.fit(data_train2, target_train2)\n",
    "\n",
    "    pred2 = clf.predict(data_test2)\n",
    "\n",
    "    precision = accuracy_score(target_test2, pred2, normalize=True)\n",
    "\n",
    "    m = confusion_matrix(target_test2, pred2)\n",
    "\n",
    "    total = m.sum()\n",
    "\n",
    "    vpositivos += m[0,0]\n",
    "    fpositivos += m[0,1]\n",
    "    vnegativos += m[1,1]\n",
    "    fnegativos += m[1,0]\n",
    "\n",
    "    print(\"Random Tree accuracy : \", precision)\n",
    "\n",
    "    media = media + precision\n",
    "\n",
    "print(\"Verdadero Positivos:\", vpositivos)\n",
    "print(\"Falsos Positivos:\", fpositivos)\n",
    "print(\"Verdadero Negativos:\", vnegativos)\n",
    "print(\"Falsos Negativos:\", fnegativos)\n",
    "\n",
    "media = media / 5\n",
    "\n",
    "print(media)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
